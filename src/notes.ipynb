{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1588,"status":"ok","timestamp":1668790698135,"user":{"displayName":"Jaime Francisco Aguayo Gonz�lez","userId":"07613071985857863916"},"user_tz":360},"id":"HIZ3bcJzlevn"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/jaime/.conda/envs/torchy/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import math\n","import os\n","import random\n","import sys\n","import h5py\n","import logging\n","import numpy as np\n","from utils.data_utils import *\n","from models.motionpredictor import *\n","import torch\n","import torch.optim as optim\n","import argparse\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1668790698136,"user":{"displayName":"Jaime Francisco Aguayo Gonz�lez","userId":"07613071985857863916"},"user_tz":360},"id":"saDlcUFylevq"},"outputs":[],"source":["args = {\n","    \"learning_rate\": 0.00001,\n","    \"learning_rate_decay_factor\": 0.95,\n","    \"learning_rate_step\": 10000,\n","    \"batch_size\": 128,\n","    \"iterations\": int(2e4),\n","    \"kl_factor\": 0.5\n","    \"test_every\": 100,\n","    \"size\": 512,\n","    \"seq_length_in\": 50,\n","    \"seq_length_out\": 25,\n","    # Directories\n","    \"data_dir\": os.path.normpath(\"../data/h3.6m/dataset\"),\n","    \"train_dir\": os.path.normpath(\"../experiments/\"),\n","    \"action\": 'all',\n","    \"log_level\": 20,\n","    \"log_file\": ''\n","}"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1668790698137,"user":{"displayName":"Jaime Francisco Aguayo Gonz�lez","userId":"07613071985857863916"},"user_tz":360},"id":"oEuQAaJolevr"},"outputs":[],"source":["train_dir = os.path.normpath(os.path.join( args['train_dir'], args['action'],\n","\t'out_{0}'.format(args['seq_length_out']),\n","\t'iterations_{0}'.format(args['iterations']),\n","\t'size_{0}'.format(args['size']),\n","\t'lr_{0}'.format(args['learning_rate'])))"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1668790698137,"user":{"displayName":"Jaime Francisco Aguayo Gonz�lez","userId":"07613071985857863916"},"user_tz":360},"id":"B3yjNsULlevs","outputId":"e1c69f2a-e717-4c9c-97dd-7f568340c435"},"outputs":[{"data":{"text/plain":["25"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["args['seq_length_out'] # Number of frames that the decoder has to predict"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1668790698138,"user":{"displayName":"Jaime Francisco Aguayo Gonz�lez","userId":"07613071985857863916"},"user_tz":360},"id":"Qu2XiA6Xlevt"},"outputs":[],"source":["# Logging\n","if args['log_file']=='':\n","\tlogging.basicConfig(format='%(levelname)s: %(message)s',level=args['log_level'])\n","else:\n","\tlogging.basicConfig(filename=args['log_file'],format='%(levelname)s: %(message)s',level=args['log_level'])"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1668790698139,"user":{"displayName":"Jaime Francisco Aguayo Gonz�lez","userId":"07613071985857863916"},"user_tz":360},"id":"d2PVjd7Ulevu"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO: NVIDIA GeForce RTX 3090\n"]}],"source":["# Detect device\n","if torch.cuda.is_available():\n","\tlogging.info(torch.cuda.get_device_name(torch.cuda.current_device()))\n","else:\n","\tlogging.info(\"cpu\")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1668790698700,"user":{"displayName":"Jaime Francisco Aguayo Gonz�lez","userId":"07613071985857863916"},"user_tz":360},"id":"0Jgb46Iblevv"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO: Train dir: ../experiments/all/out_25/iterations_20000/size_512/lr_1e-05\n"]}],"source":["logging.info(\"Train dir: \"+train_dir)\n","os.makedirs(train_dir, exist_ok=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":35859,"status":"ok","timestamp":1668790734549,"user":{"displayName":"Jaime Francisco Aguayo Gonz�lez","userId":"07613071985857863916"},"user_tz":360},"id":"bK3INBVhlevw"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO: Reading training data (seq_len_in: 50, seq_len_out 25).\n","INFO: Reading subject 1, action walking, subaction 1\n","INFO: Reading subject 1, action walking, subaction 2\n","INFO: Reading subject 1, action eating, subaction 1\n","INFO: Reading subject 1, action eating, subaction 2\n","INFO: Reading subject 1, action smoking, subaction 1\n","INFO: Reading subject 1, action smoking, subaction 2\n","INFO: Reading subject 1, action discussion, subaction 1\n","INFO: Reading subject 1, action discussion, subaction 2\n","INFO: Reading subject 1, action directions, subaction 1\n","INFO: Reading subject 1, action directions, subaction 2\n","INFO: Reading subject 1, action greeting, subaction 1\n","INFO: Reading subject 1, action greeting, subaction 2\n","INFO: Reading subject 1, action phoning, subaction 1\n","INFO: Reading subject 1, action phoning, subaction 2\n","INFO: Reading subject 1, action posing, subaction 1\n","INFO: Reading subject 1, action posing, subaction 2\n","INFO: Reading subject 1, action purchases, subaction 1\n","INFO: Reading subject 1, action purchases, subaction 2\n","INFO: Reading subject 1, action sitting, subaction 1\n","INFO: Reading subject 1, action sitting, subaction 2\n","INFO: Reading subject 1, action sittingdown, subaction 1\n","INFO: Reading subject 1, action sittingdown, subaction 2\n","INFO: Reading subject 1, action takingphoto, subaction 1\n","INFO: Reading subject 1, action takingphoto, subaction 2\n","INFO: Reading subject 1, action waiting, subaction 1\n","INFO: Reading subject 1, action waiting, subaction 2\n","INFO: Reading subject 1, action walkingdog, subaction 1\n","INFO: Reading subject 1, action walkingdog, subaction 2\n","INFO: Reading subject 1, action walkingtogether, subaction 1\n","INFO: Reading subject 1, action walkingtogether, subaction 2\n","INFO: Reading subject 6, action walking, subaction 1\n","INFO: Reading subject 6, action walking, subaction 2\n","INFO: Reading subject 6, action eating, subaction 1\n","INFO: Reading subject 6, action eating, subaction 2\n","INFO: Reading subject 6, action smoking, subaction 1\n","INFO: Reading subject 6, action smoking, subaction 2\n","INFO: Reading subject 6, action discussion, subaction 1\n","INFO: Reading subject 6, action discussion, subaction 2\n","INFO: Reading subject 6, action directions, subaction 1\n","INFO: Reading subject 6, action directions, subaction 2\n","INFO: Reading subject 6, action greeting, subaction 1\n","INFO: Reading subject 6, action greeting, subaction 2\n","INFO: Reading subject 6, action phoning, subaction 1\n","INFO: Reading subject 6, action phoning, subaction 2\n","INFO: Reading subject 6, action posing, subaction 1\n","INFO: Reading subject 6, action posing, subaction 2\n","INFO: Reading subject 6, action purchases, subaction 1\n","INFO: Reading subject 6, action purchases, subaction 2\n","INFO: Reading subject 6, action sitting, subaction 1\n","INFO: Reading subject 6, action sitting, subaction 2\n","INFO: Reading subject 6, action sittingdown, subaction 1\n","INFO: Reading subject 6, action sittingdown, subaction 2\n","INFO: Reading subject 6, action takingphoto, subaction 1\n","INFO: Reading subject 6, action takingphoto, subaction 2\n","INFO: Reading subject 6, action waiting, subaction 1\n","INFO: Reading subject 6, action waiting, subaction 2\n","INFO: Reading subject 6, action walkingdog, subaction 1\n","INFO: Reading subject 6, action walkingdog, subaction 2\n","INFO: Reading subject 6, action walkingtogether, subaction 1\n","INFO: Reading subject 6, action walkingtogether, subaction 2\n","INFO: Reading subject 7, action walking, subaction 1\n","INFO: Reading subject 7, action walking, subaction 2\n","INFO: Reading subject 7, action eating, subaction 1\n","INFO: Reading subject 7, action eating, subaction 2\n","INFO: Reading subject 7, action smoking, subaction 1\n","INFO: Reading subject 7, action smoking, subaction 2\n","INFO: Reading subject 7, action discussion, subaction 1\n","INFO: Reading subject 7, action discussion, subaction 2\n","INFO: Reading subject 7, action directions, subaction 1\n","INFO: Reading subject 7, action directions, subaction 2\n","INFO: Reading subject 7, action greeting, subaction 1\n","INFO: Reading subject 7, action greeting, subaction 2\n","INFO: Reading subject 7, action phoning, subaction 1\n","INFO: Reading subject 7, action phoning, subaction 2\n","INFO: Reading subject 7, action posing, subaction 1\n","INFO: Reading subject 7, action posing, subaction 2\n","INFO: Reading subject 7, action purchases, subaction 1\n","INFO: Reading subject 7, action purchases, subaction 2\n","INFO: Reading subject 7, action sitting, subaction 1\n","INFO: Reading subject 7, action sitting, subaction 2\n","INFO: Reading subject 7, action sittingdown, subaction 1\n","INFO: Reading subject 7, action sittingdown, subaction 2\n","INFO: Reading subject 7, action takingphoto, subaction 1\n","INFO: Reading subject 7, action takingphoto, subaction 2\n","INFO: Reading subject 7, action waiting, subaction 1\n","INFO: Reading subject 7, action waiting, subaction 2\n","INFO: Reading subject 7, action walkingdog, subaction 1\n","INFO: Reading subject 7, action walkingdog, subaction 2\n","INFO: Reading subject 7, action walkingtogether, subaction 1\n","INFO: Reading subject 7, action walkingtogether, subaction 2\n","INFO: Reading subject 9, action walking, subaction 1\n","INFO: Reading subject 9, action walking, subaction 2\n","INFO: Reading subject 9, action eating, subaction 1\n","INFO: Reading subject 9, action eating, subaction 2\n","INFO: Reading subject 9, action smoking, subaction 1\n","INFO: Reading subject 9, action smoking, subaction 2\n","INFO: Reading subject 9, action discussion, subaction 1\n","INFO: Reading subject 9, action discussion, subaction 2\n","INFO: Reading subject 9, action directions, subaction 1\n","INFO: Reading subject 9, action directions, subaction 2\n","INFO: Reading subject 9, action greeting, subaction 1\n","INFO: Reading subject 9, action greeting, subaction 2\n","INFO: Reading subject 9, action phoning, subaction 1\n","INFO: Reading subject 9, action phoning, subaction 2\n","INFO: Reading subject 9, action posing, subaction 1\n","INFO: Reading subject 9, action posing, subaction 2\n","INFO: Reading subject 9, action purchases, subaction 1\n","INFO: Reading subject 9, action purchases, subaction 2\n","INFO: Reading subject 9, action sitting, subaction 1\n","INFO: Reading subject 9, action sitting, subaction 2\n","INFO: Reading subject 9, action sittingdown, subaction 1\n","INFO: Reading subject 9, action sittingdown, subaction 2\n","INFO: Reading subject 9, action takingphoto, subaction 1\n","INFO: Reading subject 9, action takingphoto, subaction 2\n","INFO: Reading subject 9, action waiting, subaction 1\n","INFO: Reading subject 9, action waiting, subaction 2\n","INFO: Reading subject 9, action walkingdog, subaction 1\n","INFO: Reading subject 9, action walkingdog, subaction 2\n","INFO: Reading subject 9, action walkingtogether, subaction 1\n","INFO: Reading subject 9, action walkingtogether, subaction 2\n","INFO: Reading subject 11, action walking, subaction 1\n","INFO: Reading subject 11, action walking, subaction 2\n","INFO: Reading subject 11, action eating, subaction 1\n","INFO: Reading subject 11, action eating, subaction 2\n","INFO: Reading subject 11, action smoking, subaction 1\n","INFO: Reading subject 11, action smoking, subaction 2\n","INFO: Reading subject 11, action discussion, subaction 1\n","INFO: Reading subject 11, action discussion, subaction 2\n","INFO: Reading subject 11, action directions, subaction 1\n","INFO: Reading subject 11, action directions, subaction 2\n","INFO: Reading subject 11, action greeting, subaction 1\n","INFO: Reading subject 11, action greeting, subaction 2\n","INFO: Reading subject 11, action phoning, subaction 1\n","INFO: Reading subject 11, action phoning, subaction 2\n","INFO: Reading subject 11, action posing, subaction 1\n","INFO: Reading subject 11, action posing, subaction 2\n","INFO: Reading subject 11, action purchases, subaction 1\n","INFO: Reading subject 11, action purchases, subaction 2\n","INFO: Reading subject 11, action sitting, subaction 1\n","INFO: Reading subject 11, action sitting, subaction 2\n","INFO: Reading subject 11, action sittingdown, subaction 1\n","INFO: Reading subject 11, action sittingdown, subaction 2\n","INFO: Reading subject 11, action takingphoto, subaction 1\n","INFO: Reading subject 11, action takingphoto, subaction 2\n","INFO: Reading subject 11, action waiting, subaction 1\n","INFO: Reading subject 11, action waiting, subaction 2\n","INFO: Reading subject 11, action walkingdog, subaction 1\n","INFO: Reading subject 11, action walkingdog, subaction 2\n","INFO: Reading subject 11, action walkingtogether, subaction 1\n","INFO: Reading subject 11, action walkingtogether, subaction 2\n","INFO: Reading subject 5, action walking, subaction 1\n","INFO: Reading subject 5, action walking, subaction 2\n","INFO: Reading subject 5, action eating, subaction 1\n","INFO: Reading subject 5, action eating, subaction 2\n","INFO: Reading subject 5, action smoking, subaction 1\n","INFO: Reading subject 5, action smoking, subaction 2\n","INFO: Reading subject 5, action discussion, subaction 1\n","INFO: Reading subject 5, action discussion, subaction 2\n","INFO: Reading subject 5, action directions, subaction 1\n","INFO: Reading subject 5, action directions, subaction 2\n","INFO: Reading subject 5, action greeting, subaction 1\n","INFO: Reading subject 5, action greeting, subaction 2\n","INFO: Reading subject 5, action phoning, subaction 1\n","INFO: Reading subject 5, action phoning, subaction 2\n","INFO: Reading subject 5, action posing, subaction 1\n","INFO: Reading subject 5, action posing, subaction 2\n","INFO: Reading subject 5, action purchases, subaction 1\n","INFO: Reading subject 5, action purchases, subaction 2\n","INFO: Reading subject 5, action sitting, subaction 1\n","INFO: Reading subject 5, action sitting, subaction 2\n","INFO: Reading subject 5, action sittingdown, subaction 1\n","INFO: Reading subject 5, action sittingdown, subaction 2\n","INFO: Reading subject 5, action takingphoto, subaction 1\n","INFO: Reading subject 5, action takingphoto, subaction 2\n","INFO: Reading subject 5, action waiting, subaction 1\n","INFO: Reading subject 5, action waiting, subaction 2\n","INFO: Reading subject 5, action walkingdog, subaction 1\n","INFO: Reading subject 5, action walkingdog, subaction 2\n","INFO: Reading subject 5, action walkingtogether, subaction 1\n","INFO: Reading subject 5, action walkingtogether, subaction 2\n"]}],"source":["\"\"\"Train a seq2seq model on human motion\"\"\"\n","# Set of actions\n","actions           = define_actions( args['action'] ) # like \"walking\", \"eating\", \"smoking\", \"discussion\",  \"directions\", etc\n","number_of_actions = len( actions )\n","\n","# Loads data for training/testing and normalizes it\n","# seq_length_in: number of frames to use in the burn-in sequence\n","# seq_length_out: number of frames to use in the output sequence\n","train_set, test_set, data_mean, data_std, dim_to_ignore, dim_to_use = read_all_data(actions, args['seq_length_in'], args['seq_length_out'], args['data_dir'])"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":2936,"status":"ok","timestamp":1668790737479,"user":{"displayName":"Jaime Francisco Aguayo Gonz�lez","userId":"07613071985857863916"},"user_tz":360},"id":"GxZH_5GAlevy"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO: Input size is 69\n"]}],"source":["# Create model for training only\n","model = MotionPredictor(args['seq_length_in'], args['seq_length_out'],\n","    args['size'], # hidden layer size\n","    args['batch_size'], args['learning_rate'],\n","    args['learning_rate_decay_factor'],\n","    len( actions ))\n","model = model.to(device)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1668790737480,"user":{"displayName":"Jaime Francisco Aguayo Gonz�lez","userId":"07613071985857863916"},"user_tz":360},"id":"IzGm6pa4levz","outputId":"d5266ae0-cc96-46d6-c612-cbc748ef106d"},"outputs":[{"data":{"text/plain":["MotionPredictor(\n","  (cell): GRUCell(69, 512)\n","  (fc1): Linear(in_features=512, out_features=69, bias=True)\n","  (fc_mean): Linear(in_features=512, out_features=512, bias=True)\n","  (fc_var): Linear(in_features=512, out_features=512, bias=True)\n","  (atten): Sequential(\n","    (0): Linear(in_features=581, out_features=512, bias=True)\n","    (1): Softmax(dim=1)\n","  )\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1668790737481,"user":{"displayName":"Jaime Francisco Aguayo Gonz�lez","userId":"07613071985857863916"},"user_tz":360},"id":"NXoilicSlev0"},"outputs":[],"source":["# This is the training loop\n","loss, val_loss = 0.0, 0.0\n","current_step   = 0\n","all_losses     = []\n","all_val_losses = []\n","\n","# The optimizer\n","#optimiser = optim.SGD(model.parameters(), lr=args.learning_rate)\n","optimiser = optim.Adam(model.parameters(), lr=args['learning_rate'], betas = (0.9, 0.999))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":604173,"status":"ok","timestamp":1668791341645,"user":{"displayName":"Jaime Francisco Aguayo Gonz�lez","userId":"07613071985857863916"},"user_tz":360},"id":"C_IRed5nlev1","outputId":"fe047833-ca02-443f-db26-101792f9e85c"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO: step 0000; step_loss: 8.5086 (1.1799, 7.3286)\n","INFO: step 0100; step_loss: 7.5428 (0.9194, 6.6234)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         100\n","Learning rate:       0.0000\n","Train loss avg:      7.9074\n","--------------------------\n","Val loss:            0.9482\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 0200; step_loss: 5.6897 (0.6811, 5.0086)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         200\n","Learning rate:       0.0000\n","Train loss avg:      6.4343\n","--------------------------\n","Val loss:            0.7778\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 0300; step_loss: 4.9939 (0.5854, 4.4085)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         300\n","Learning rate:       0.0000\n","Train loss avg:      5.4470\n","--------------------------\n","Val loss:            0.6990\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 0400; step_loss: 4.1492 (0.5373, 3.6119)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         400\n","Learning rate:       0.0000\n","Train loss avg:      4.7007\n","--------------------------\n","Val loss:            0.5792\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 0500; step_loss: 4.3678 (0.5279, 3.8398)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         500\n","Learning rate:       0.0000\n","Train loss avg:      4.1683\n","--------------------------\n","Val loss:            0.5702\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 0600; step_loss: 3.4867 (0.4903, 2.9963)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         600\n","Learning rate:       0.0000\n","Train loss avg:      3.7229\n","--------------------------\n","Val loss:            0.4809\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 0700; step_loss: 2.8956 (0.3998, 2.4958)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         700\n","Learning rate:       0.0000\n","Train loss avg:      3.3041\n","--------------------------\n","Val loss:            0.5528\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 0800; step_loss: 3.1670 (0.4452, 2.7218)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         800\n","Learning rate:       0.0000\n","Train loss avg:      3.0430\n","--------------------------\n","Val loss:            0.5050\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 0900; step_loss: 2.6541 (0.4298, 2.2243)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         900\n","Learning rate:       0.0000\n","Train loss avg:      2.7465\n","--------------------------\n","Val loss:            0.4270\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 1000; step_loss: 2.2940 (0.3270, 1.9670)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         1000\n","Learning rate:       0.0000\n","Train loss avg:      2.5542\n","--------------------------\n","Val loss:            0.4743\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 1100; step_loss: 2.5268 (0.3901, 2.1368)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         1100\n","Learning rate:       0.0000\n","Train loss avg:      2.3476\n","--------------------------\n","Val loss:            0.4570\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 1200; step_loss: 2.2007 (0.4006, 1.8001)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         1200\n","Learning rate:       0.0000\n","Train loss avg:      2.2022\n","--------------------------\n","Val loss:            0.3842\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 1300; step_loss: 1.8705 (0.3341, 1.5364)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         1300\n","Learning rate:       0.0000\n","Train loss avg:      2.0516\n","--------------------------\n","Val loss:            0.4174\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 1400; step_loss: 1.8447 (0.3453, 1.4994)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         1400\n","Learning rate:       0.0000\n","Train loss avg:      1.9095\n","--------------------------\n","Val loss:            0.3925\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 1500; step_loss: 1.8359 (0.3759, 1.4601)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         1500\n","Learning rate:       0.0000\n","Train loss avg:      1.7833\n","--------------------------\n","Val loss:            0.3287\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 1600; step_loss: 1.5693 (0.3421, 1.2272)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         1600\n","Learning rate:       0.0000\n","Train loss avg:      1.7125\n","--------------------------\n","Val loss:            0.3154\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 1700; step_loss: 1.4906 (0.3095, 1.1811)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         1700\n","Learning rate:       0.0000\n","Train loss avg:      1.6090\n","--------------------------\n","Val loss:            0.3566\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 1800; step_loss: 1.5017 (0.3193, 1.1824)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         1800\n","Learning rate:       0.0000\n","Train loss avg:      1.5194\n","--------------------------\n","Val loss:            0.3262\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 1900; step_loss: 1.6451 (0.3678, 1.2773)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         1900\n","Learning rate:       0.0000\n","Train loss avg:      1.4232\n","--------------------------\n","Val loss:            0.3260\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 2000; step_loss: 1.3882 (0.3370, 1.0512)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         2000\n","Learning rate:       0.0000\n","Train loss avg:      1.3753\n","--------------------------\n","Val loss:            0.3439\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 2100; step_loss: 1.2106 (0.3208, 0.8899)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         2100\n","Learning rate:       0.0000\n","Train loss avg:      1.2881\n","--------------------------\n","Val loss:            0.3043\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 2200; step_loss: 1.2304 (0.3254, 0.9051)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         2200\n","Learning rate:       0.0000\n","Train loss avg:      1.2294\n","--------------------------\n","Val loss:            0.3209\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 2300; step_loss: 1.1468 (0.2623, 0.8845)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         2300\n","Learning rate:       0.0000\n","Train loss avg:      1.1726\n","--------------------------\n","Val loss:            0.3500\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 2400; step_loss: 1.1152 (0.2980, 0.8173)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         2400\n","Learning rate:       0.0000\n","Train loss avg:      1.1276\n","--------------------------\n","Val loss:            0.3405\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 2500; step_loss: 1.3168 (0.3963, 0.9204)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         2500\n","Learning rate:       0.0000\n","Train loss avg:      1.0776\n","--------------------------\n","Val loss:            0.3001\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 2600; step_loss: 0.9548 (0.2566, 0.6982)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         2600\n","Learning rate:       0.0000\n","Train loss avg:      1.0282\n","--------------------------\n","Val loss:            0.3325\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 2700; step_loss: 0.8698 (0.2371, 0.6327)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         2700\n","Learning rate:       0.0000\n","Train loss avg:      0.9917\n","--------------------------\n","Val loss:            0.3100\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 2800; step_loss: 0.9737 (0.2722, 0.7015)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         2800\n","Learning rate:       0.0000\n","Train loss avg:      0.9497\n","--------------------------\n","Val loss:            0.3082\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 2900; step_loss: 0.8771 (0.2729, 0.6041)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         2900\n","Learning rate:       0.0000\n","Train loss avg:      0.9247\n","--------------------------\n","Val loss:            0.2971\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 3000; step_loss: 0.8559 (0.2939, 0.5621)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         3000\n","Learning rate:       0.0000\n","Train loss avg:      0.8875\n","--------------------------\n","Val loss:            0.3134\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 3100; step_loss: 0.7778 (0.2660, 0.5118)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         3100\n","Learning rate:       0.0000\n","Train loss avg:      0.8544\n","--------------------------\n","Val loss:            0.3215\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 3200; step_loss: 0.7402 (0.2379, 0.5022)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         3200\n","Learning rate:       0.0000\n","Train loss avg:      0.8091\n","--------------------------\n","Val loss:            0.3099\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 3300; step_loss: 0.8208 (0.3145, 0.5063)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         3300\n","Learning rate:       0.0000\n","Train loss avg:      0.7877\n","--------------------------\n","Val loss:            0.2857\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 3400; step_loss: 0.7510 (0.2657, 0.4853)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         3400\n","Learning rate:       0.0000\n","Train loss avg:      0.7565\n","--------------------------\n","Val loss:            0.3213\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 3500; step_loss: 0.6800 (0.2703, 0.4097)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         3500\n","Learning rate:       0.0000\n","Train loss avg:      0.7368\n","--------------------------\n","Val loss:            0.2765\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 3600; step_loss: 0.6924 (0.2718, 0.4206)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         3600\n","Learning rate:       0.0000\n","Train loss avg:      0.7245\n","--------------------------\n","Val loss:            0.2490\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 3700; step_loss: 0.7140 (0.2969, 0.4171)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         3700\n","Learning rate:       0.0000\n","Train loss avg:      0.6905\n","--------------------------\n","Val loss:            0.2957\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 3800; step_loss: 0.6247 (0.2605, 0.3642)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         3800\n","Learning rate:       0.0000\n","Train loss avg:      0.6789\n","--------------------------\n","Val loss:            0.3168\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 3900; step_loss: 0.7482 (0.3441, 0.4041)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         3900\n","Learning rate:       0.0000\n","Train loss avg:      0.6612\n","--------------------------\n","Val loss:            0.3050\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 4000; step_loss: 0.5725 (0.2435, 0.3290)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         4000\n","Learning rate:       0.0000\n","Train loss avg:      0.6354\n","--------------------------\n","Val loss:            0.3069\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 4100; step_loss: 0.5728 (0.2373, 0.3355)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         4100\n","Learning rate:       0.0000\n","Train loss avg:      0.6179\n","--------------------------\n","Val loss:            0.3228\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 4200; step_loss: 0.6224 (0.3041, 0.3183)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         4200\n","Learning rate:       0.0000\n","Train loss avg:      0.6024\n","--------------------------\n","Val loss:            0.2739\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 4300; step_loss: 0.5526 (0.2611, 0.2915)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         4300\n","Learning rate:       0.0000\n","Train loss avg:      0.5702\n","--------------------------\n","Val loss:            0.3065\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 4400; step_loss: 0.5629 (0.2753, 0.2876)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         4400\n","Learning rate:       0.0000\n","Train loss avg:      0.5723\n","--------------------------\n","Val loss:            0.2934\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 4500; step_loss: 0.5661 (0.3013, 0.2648)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         4500\n","Learning rate:       0.0000\n","Train loss avg:      0.5484\n","--------------------------\n","Val loss:            0.2693\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 4600; step_loss: 0.5449 (0.2589, 0.2861)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         4600\n","Learning rate:       0.0000\n","Train loss avg:      0.5408\n","--------------------------\n","Val loss:            0.2701\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 4700; step_loss: 0.4728 (0.2339, 0.2389)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         4700\n","Learning rate:       0.0000\n","Train loss avg:      0.5241\n","--------------------------\n","Val loss:            0.2677\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 4800; step_loss: 0.4146 (0.1972, 0.2174)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         4800\n","Learning rate:       0.0000\n","Train loss avg:      0.5064\n","--------------------------\n","Val loss:            0.2946\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 4900; step_loss: 0.5023 (0.2684, 0.2339)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         4900\n","Learning rate:       0.0000\n","Train loss avg:      0.4977\n","--------------------------\n","Val loss:            0.2496\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 5000; step_loss: 0.4462 (0.2467, 0.1995)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         5000\n","Learning rate:       0.0000\n","Train loss avg:      0.4831\n","--------------------------\n","Val loss:            0.3358\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 5100; step_loss: 0.4766 (0.2730, 0.2037)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         5100\n","Learning rate:       0.0000\n","Train loss avg:      0.4696\n","--------------------------\n","Val loss:            0.2737\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 5200; step_loss: 0.4545 (0.2681, 0.1863)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         5200\n","Learning rate:       0.0000\n","Train loss avg:      0.4693\n","--------------------------\n","Val loss:            0.2393\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 5300; step_loss: 0.3915 (0.2309, 0.1607)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         5300\n","Learning rate:       0.0000\n","Train loss avg:      0.4599\n","--------------------------\n","Val loss:            0.2474\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 5400; step_loss: 0.3827 (0.2205, 0.1622)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         5400\n","Learning rate:       0.0000\n","Train loss avg:      0.4392\n","--------------------------\n","Val loss:            0.3202\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 5500; step_loss: 0.4524 (0.2956, 0.1568)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         5500\n","Learning rate:       0.0000\n","Train loss avg:      0.4239\n","--------------------------\n","Val loss:            0.2815\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 5600; step_loss: 0.3723 (0.2130, 0.1593)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         5600\n","Learning rate:       0.0000\n","Train loss avg:      0.4268\n","--------------------------\n","Val loss:            0.2873\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 5700; step_loss: 0.3666 (0.2196, 0.1470)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         5700\n","Learning rate:       0.0000\n","Train loss avg:      0.4209\n","--------------------------\n","Val loss:            0.2965\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 5800; step_loss: 0.3851 (0.2219, 0.1632)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         5800\n","Learning rate:       0.0000\n","Train loss avg:      0.4204\n","--------------------------\n","Val loss:            0.3055\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 5900; step_loss: 0.3674 (0.2458, 0.1216)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         5900\n","Learning rate:       0.0000\n","Train loss avg:      0.4057\n","--------------------------\n","Val loss:            0.2982\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 6000; step_loss: 0.4724 (0.3332, 0.1392)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         6000\n","Learning rate:       0.0000\n","Train loss avg:      0.3922\n","--------------------------\n","Val loss:            0.2583\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 6100; step_loss: 0.3205 (0.2072, 0.1133)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         6100\n","Learning rate:       0.0000\n","Train loss avg:      0.3847\n","--------------------------\n","Val loss:            0.2582\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 6200; step_loss: 0.5057 (0.3544, 0.1513)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         6200\n","Learning rate:       0.0000\n","Train loss avg:      0.3768\n","--------------------------\n","Val loss:            0.3062\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 6300; step_loss: 0.3009 (0.2002, 0.1006)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         6300\n","Learning rate:       0.0000\n","Train loss avg:      0.3772\n","--------------------------\n","Val loss:            0.2734\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 6400; step_loss: 0.3316 (0.2370, 0.0946)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         6400\n","Learning rate:       0.0000\n","Train loss avg:      0.3704\n","--------------------------\n","Val loss:            0.2996\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 6500; step_loss: 0.3761 (0.2662, 0.1099)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         6500\n","Learning rate:       0.0000\n","Train loss avg:      0.3625\n","--------------------------\n","Val loss:            0.3140\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 6600; step_loss: 0.3003 (0.2136, 0.0867)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         6600\n","Learning rate:       0.0000\n","Train loss avg:      0.3605\n","--------------------------\n","Val loss:            0.2502\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 6700; step_loss: 0.3379 (0.2344, 0.1036)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         6700\n","Learning rate:       0.0000\n","Train loss avg:      0.3557\n","--------------------------\n","Val loss:            0.2934\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 6800; step_loss: 0.3261 (0.2385, 0.0877)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         6800\n","Learning rate:       0.0000\n","Train loss avg:      0.3503\n","--------------------------\n","Val loss:            0.2910\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 6900; step_loss: 0.3161 (0.2317, 0.0844)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         6900\n","Learning rate:       0.0000\n","Train loss avg:      0.3406\n","--------------------------\n","Val loss:            0.3185\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 7000; step_loss: 0.3060 (0.2303, 0.0757)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         7000\n","Learning rate:       0.0000\n","Train loss avg:      0.3434\n","--------------------------\n","Val loss:            0.2660\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 7100; step_loss: 0.4249 (0.3312, 0.0937)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         7100\n","Learning rate:       0.0000\n","Train loss avg:      0.3361\n","--------------------------\n","Val loss:            0.2905\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 7200; step_loss: 0.3367 (0.2538, 0.0829)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         7200\n","Learning rate:       0.0000\n","Train loss avg:      0.3382\n","--------------------------\n","Val loss:            0.3015\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 7300; step_loss: 0.3284 (0.2488, 0.0795)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         7300\n","Learning rate:       0.0000\n","Train loss avg:      0.3328\n","--------------------------\n","Val loss:            0.2764\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 7400; step_loss: 0.3224 (0.2538, 0.0686)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         7400\n","Learning rate:       0.0000\n","Train loss avg:      0.3296\n","--------------------------\n","Val loss:            0.3060\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 7500; step_loss: 0.2813 (0.2211, 0.0602)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         7500\n","Learning rate:       0.0000\n","Train loss avg:      0.3244\n","--------------------------\n","Val loss:            0.3083\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 7600; step_loss: 0.3061 (0.2381, 0.0680)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         7600\n","Learning rate:       0.0000\n","Train loss avg:      0.3261\n","--------------------------\n","Val loss:            0.2939\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 7700; step_loss: 0.3103 (0.2466, 0.0637)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         7700\n","Learning rate:       0.0000\n","Train loss avg:      0.3172\n","--------------------------\n","Val loss:            0.2746\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 7800; step_loss: 0.3307 (0.2656, 0.0651)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         7800\n","Learning rate:       0.0000\n","Train loss avg:      0.3118\n","--------------------------\n","Val loss:            0.3387\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 7900; step_loss: 0.3214 (0.2624, 0.0591)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         7900\n","Learning rate:       0.0000\n","Train loss avg:      0.3099\n","--------------------------\n","Val loss:            0.2647\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 8000; step_loss: 0.2605 (0.2109, 0.0497)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         8000\n","Learning rate:       0.0000\n","Train loss avg:      0.3103\n","--------------------------\n","Val loss:            0.3015\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 8100; step_loss: 0.3258 (0.2671, 0.0586)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         8100\n","Learning rate:       0.0000\n","Train loss avg:      0.3051\n","--------------------------\n","Val loss:            0.2717\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 8200; step_loss: 0.2511 (0.2039, 0.0472)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         8200\n","Learning rate:       0.0000\n","Train loss avg:      0.2994\n","--------------------------\n","Val loss:            0.3006\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 8300; step_loss: 0.3371 (0.2759, 0.0612)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         8300\n","Learning rate:       0.0000\n","Train loss avg:      0.2995\n","--------------------------\n","Val loss:            0.2530\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 8400; step_loss: 0.2657 (0.2191, 0.0465)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         8400\n","Learning rate:       0.0000\n","Train loss avg:      0.3012\n","--------------------------\n","Val loss:            0.2989\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 8500; step_loss: 0.2998 (0.2545, 0.0453)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         8500\n","Learning rate:       0.0000\n","Train loss avg:      0.2961\n","--------------------------\n","Val loss:            0.2879\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 8600; step_loss: 0.2625 (0.2259, 0.0365)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         8600\n","Learning rate:       0.0000\n","Train loss avg:      0.2935\n","--------------------------\n","Val loss:            0.3118\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 8700; step_loss: 0.2876 (0.2457, 0.0419)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         8700\n","Learning rate:       0.0000\n","Train loss avg:      0.2967\n","--------------------------\n","Val loss:            0.2779\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 8800; step_loss: 0.2313 (0.1955, 0.0357)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         8800\n","Learning rate:       0.0000\n","Train loss avg:      0.2927\n","--------------------------\n","Val loss:            0.2747\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 8900; step_loss: 0.2838 (0.2351, 0.0487)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         8900\n","Learning rate:       0.0000\n","Train loss avg:      0.2912\n","--------------------------\n","Val loss:            0.2739\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 9000; step_loss: 0.2574 (0.2219, 0.0355)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         9000\n","Learning rate:       0.0000\n","Train loss avg:      0.2837\n","--------------------------\n","Val loss:            0.2830\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 9100; step_loss: 0.2643 (0.2323, 0.0320)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         9100\n","Learning rate:       0.0000\n","Train loss avg:      0.2841\n","--------------------------\n","Val loss:            0.2605\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 9200; step_loss: 0.2631 (0.2333, 0.0299)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         9200\n","Learning rate:       0.0000\n","Train loss avg:      0.2793\n","--------------------------\n","Val loss:            0.2661\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 9300; step_loss: 0.2259 (0.1949, 0.0310)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         9300\n","Learning rate:       0.0000\n","Train loss avg:      0.2839\n","--------------------------\n","Val loss:            0.3206\n","============================\n","\n","\n","============================\n","Global step:         9400\n","Learning rate:       0.0000\n","Train loss avg:      0.2855\n","--------------------------\n","Val loss:            0.3032\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 9400; step_loss: 0.2663 (0.2366, 0.0297)\n","INFO: step 9500; step_loss: 0.2779 (0.2471, 0.0307)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         9500\n","Learning rate:       0.0000\n","Train loss avg:      0.2820\n","--------------------------\n","Val loss:            0.2990\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 9600; step_loss: 0.3386 (0.3119, 0.0266)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         9600\n","Learning rate:       0.0000\n","Train loss avg:      0.2794\n","--------------------------\n","Val loss:            0.2482\n","============================\n","\n","\n","============================\n","Global step:         9700\n","Learning rate:       0.0000\n","Train loss avg:      0.2723\n","--------------------------\n","Val loss:            0.3041\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 9700; step_loss: 0.2829 (0.2498, 0.0331)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         9800\n","Learning rate:       0.0000\n","Train loss avg:      0.2741\n","--------------------------\n","Val loss:            0.2984\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 9800; step_loss: 0.2453 (0.2196, 0.0256)\n","INFO: step 9900; step_loss: 0.2718 (0.2449, 0.0270)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         9900\n","Learning rate:       0.0000\n","Train loss avg:      0.2724\n","--------------------------\n","Val loss:            0.2887\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 10000; step_loss: 0.2633 (0.2386, 0.0246)\n"]},{"name":"stdout","output_type":"stream","text":["Decay learning rate. New value at 9.5e-06\n","\n","============================\n","Global step:         10000\n","Learning rate:       0.0000\n","Train loss avg:      0.2692\n","--------------------------\n","Val loss:            0.3042\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 10100; step_loss: 0.3393 (0.3139, 0.0255)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         10100\n","Learning rate:       0.0000\n","Train loss avg:      0.2747\n","--------------------------\n","Val loss:            0.2961\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 10200; step_loss: 0.2450 (0.2229, 0.0220)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         10200\n","Learning rate:       0.0000\n","Train loss avg:      0.2638\n","--------------------------\n","Val loss:            0.2779\n","============================\n","\n","\n","============================\n","Global step:         10300\n","Learning rate:       0.0000\n","Train loss avg:      0.2714\n","--------------------------\n","Val loss:            0.3054\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 10300; step_loss: 0.3218 (0.2993, 0.0224)\n","INFO: step 10400; step_loss: 0.3684 (0.3428, 0.0256)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         10400\n","Learning rate:       0.0000\n","Train loss avg:      0.2669\n","--------------------------\n","Val loss:            0.2704\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 10500; step_loss: 0.2395 (0.2229, 0.0166)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         10500\n","Learning rate:       0.0000\n","Train loss avg:      0.2667\n","--------------------------\n","Val loss:            0.2817\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 10600; step_loss: 0.2364 (0.2183, 0.0181)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         10600\n","Learning rate:       0.0000\n","Train loss avg:      0.2706\n","--------------------------\n","Val loss:            0.2900\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 10700; step_loss: 0.2657 (0.2492, 0.0165)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         10700\n","Learning rate:       0.0000\n","Train loss avg:      0.2645\n","--------------------------\n","Val loss:            0.2979\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 10800; step_loss: 0.3147 (0.2967, 0.0181)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         10800\n","Learning rate:       0.0000\n","Train loss avg:      0.2628\n","--------------------------\n","Val loss:            0.2348\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 10900; step_loss: 0.3333 (0.3148, 0.0185)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         10900\n","Learning rate:       0.0000\n","Train loss avg:      0.2590\n","--------------------------\n","Val loss:            0.2584\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 11000; step_loss: 0.2493 (0.2355, 0.0138)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         11000\n","Learning rate:       0.0000\n","Train loss avg:      0.2637\n","--------------------------\n","Val loss:            0.2946\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 11100; step_loss: 0.3048 (0.2909, 0.0140)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         11100\n","Learning rate:       0.0000\n","Train loss avg:      0.2624\n","--------------------------\n","Val loss:            0.2688\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 11200; step_loss: 0.2937 (0.2761, 0.0176)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         11200\n","Learning rate:       0.0000\n","Train loss avg:      0.2613\n","--------------------------\n","Val loss:            0.2844\n","============================\n","\n","\n","============================\n","Global step:         11300\n","Learning rate:       0.0000\n","Train loss avg:      0.2594\n","--------------------------\n","Val loss:            0.2741\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 11300; step_loss: 0.3442 (0.3286, 0.0157)\n","INFO: step 11400; step_loss: 0.3046 (0.2897, 0.0149)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         11400\n","Learning rate:       0.0000\n","Train loss avg:      0.2601\n","--------------------------\n","Val loss:            0.2866\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 11500; step_loss: 0.2470 (0.2314, 0.0156)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         11500\n","Learning rate:       0.0000\n","Train loss avg:      0.2642\n","--------------------------\n","Val loss:            0.2956\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 11600; step_loss: 0.2792 (0.2652, 0.0140)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         11600\n","Learning rate:       0.0000\n","Train loss avg:      0.2551\n","--------------------------\n","Val loss:            0.2630\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 11700; step_loss: 0.2366 (0.2259, 0.0107)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         11700\n","Learning rate:       0.0000\n","Train loss avg:      0.2580\n","--------------------------\n","Val loss:            0.2802\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 11800; step_loss: 0.2538 (0.2433, 0.0105)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         11800\n","Learning rate:       0.0000\n","Train loss avg:      0.2595\n","--------------------------\n","Val loss:            0.2777\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 11900; step_loss: 0.3002 (0.2885, 0.0116)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         11900\n","Learning rate:       0.0000\n","Train loss avg:      0.2535\n","--------------------------\n","Val loss:            0.2828\n","============================\n","\n","\n","============================\n","Global step:         12000\n","Learning rate:       0.0000\n","Train loss avg:      0.2554\n","--------------------------\n","Val loss:            0.2896\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 12000; step_loss: 0.2042 (0.1944, 0.0098)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         12100\n","Learning rate:       0.0000\n","Train loss avg:      0.2517\n","--------------------------\n","Val loss:            0.2671\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 12100; step_loss: 0.2233 (0.2150, 0.0082)\n","INFO: step 12200; step_loss: 0.2731 (0.2644, 0.0088)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         12200\n","Learning rate:       0.0000\n","Train loss avg:      0.2477\n","--------------------------\n","Val loss:            0.3066\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 12300; step_loss: 0.2340 (0.2257, 0.0083)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         12300\n","Learning rate:       0.0000\n","Train loss avg:      0.2548\n","--------------------------\n","Val loss:            0.3298\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 12400; step_loss: 0.2136 (0.2065, 0.0071)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         12400\n","Learning rate:       0.0000\n","Train loss avg:      0.2540\n","--------------------------\n","Val loss:            0.2744\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 12500; step_loss: 0.2353 (0.2282, 0.0071)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         12500\n","Learning rate:       0.0000\n","Train loss avg:      0.2492\n","--------------------------\n","Val loss:            0.2937\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 12600; step_loss: 0.2419 (0.2345, 0.0075)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         12600\n","Learning rate:       0.0000\n","Train loss avg:      0.2511\n","--------------------------\n","Val loss:            0.2761\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 12700; step_loss: 0.2552 (0.2481, 0.0071)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         12700\n","Learning rate:       0.0000\n","Train loss avg:      0.2481\n","--------------------------\n","Val loss:            0.3220\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 12800; step_loss: 0.2285 (0.2218, 0.0066)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         12800\n","Learning rate:       0.0000\n","Train loss avg:      0.2461\n","--------------------------\n","Val loss:            0.2694\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 12900; step_loss: 0.2582 (0.2521, 0.0061)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         12900\n","Learning rate:       0.0000\n","Train loss avg:      0.2504\n","--------------------------\n","Val loss:            0.2651\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 13000; step_loss: 0.2187 (0.2120, 0.0067)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         13000\n","Learning rate:       0.0000\n","Train loss avg:      0.2486\n","--------------------------\n","Val loss:            0.2918\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 13100; step_loss: 0.2256 (0.2181, 0.0075)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         13100\n","Learning rate:       0.0000\n","Train loss avg:      0.2474\n","--------------------------\n","Val loss:            0.2486\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 13200; step_loss: 0.2310 (0.2251, 0.0059)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         13200\n","Learning rate:       0.0000\n","Train loss avg:      0.2510\n","--------------------------\n","Val loss:            0.2949\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 13300; step_loss: 0.2310 (0.2254, 0.0057)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         13300\n","Learning rate:       0.0000\n","Train loss avg:      0.2470\n","--------------------------\n","Val loss:            0.2612\n","============================\n","\n","\n","============================\n","Global step:         13400\n","Learning rate:       0.0000\n","Train loss avg:      0.2465\n","--------------------------\n","Val loss:            0.2860\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 13400; step_loss: 0.2165 (0.2110, 0.0055)\n","INFO: step 13500; step_loss: 0.2657 (0.2597, 0.0060)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         13500\n","Learning rate:       0.0000\n","Train loss avg:      0.2461\n","--------------------------\n","Val loss:            0.3031\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 13600; step_loss: 0.2310 (0.2259, 0.0051)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         13600\n","Learning rate:       0.0000\n","Train loss avg:      0.2446\n","--------------------------\n","Val loss:            0.2588\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 13700; step_loss: 0.2574 (0.2523, 0.0050)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         13700\n","Learning rate:       0.0000\n","Train loss avg:      0.2472\n","--------------------------\n","Val loss:            0.2569\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 13800; step_loss: 0.2444 (0.2396, 0.0048)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         13800\n","Learning rate:       0.0000\n","Train loss avg:      0.2461\n","--------------------------\n","Val loss:            0.2993\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 13900; step_loss: 0.2021 (0.1982, 0.0039)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         13900\n","Learning rate:       0.0000\n","Train loss avg:      0.2483\n","--------------------------\n","Val loss:            0.2922\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 14000; step_loss: 0.2144 (0.2098, 0.0046)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         14000\n","Learning rate:       0.0000\n","Train loss avg:      0.2473\n","--------------------------\n","Val loss:            0.3005\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 14100; step_loss: 0.2457 (0.2415, 0.0043)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         14100\n","Learning rate:       0.0000\n","Train loss avg:      0.2428\n","--------------------------\n","Val loss:            0.2811\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 14200; step_loss: 0.2729 (0.2680, 0.0050)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         14200\n","Learning rate:       0.0000\n","Train loss avg:      0.2497\n","--------------------------\n","Val loss:            0.2662\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 14300; step_loss: 0.2217 (0.2182, 0.0035)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         14300\n","Learning rate:       0.0000\n","Train loss avg:      0.2451\n","--------------------------\n","Val loss:            0.2867\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 14400; step_loss: 0.2436 (0.2385, 0.0051)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         14400\n","Learning rate:       0.0000\n","Train loss avg:      0.2434\n","--------------------------\n","Val loss:            0.2720\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 14500; step_loss: 0.2775 (0.2740, 0.0035)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         14500\n","Learning rate:       0.0000\n","Train loss avg:      0.2446\n","--------------------------\n","Val loss:            0.2553\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 14600; step_loss: 0.2445 (0.2413, 0.0032)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         14600\n","Learning rate:       0.0000\n","Train loss avg:      0.2439\n","--------------------------\n","Val loss:            0.2683\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 14700; step_loss: 0.2496 (0.2464, 0.0032)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         14700\n","Learning rate:       0.0000\n","Train loss avg:      0.2415\n","--------------------------\n","Val loss:            0.2461\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 14800; step_loss: 0.2388 (0.2361, 0.0027)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         14800\n","Learning rate:       0.0000\n","Train loss avg:      0.2457\n","--------------------------\n","Val loss:            0.3092\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 14900; step_loss: 0.1879 (0.1854, 0.0025)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         14900\n","Learning rate:       0.0000\n","Train loss avg:      0.2454\n","--------------------------\n","Val loss:            0.2828\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 15000; step_loss: 0.2335 (0.2309, 0.0026)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         15000\n","Learning rate:       0.0000\n","Train loss avg:      0.2406\n","--------------------------\n","Val loss:            0.3001\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 15100; step_loss: 0.2089 (0.2064, 0.0025)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         15100\n","Learning rate:       0.0000\n","Train loss avg:      0.2424\n","--------------------------\n","Val loss:            0.2513\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 15200; step_loss: 0.2448 (0.2424, 0.0024)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         15200\n","Learning rate:       0.0000\n","Train loss avg:      0.2458\n","--------------------------\n","Val loss:            0.3142\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 15300; step_loss: 0.2978 (0.2943, 0.0035)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         15300\n","Learning rate:       0.0000\n","Train loss avg:      0.2381\n","--------------------------\n","Val loss:            0.2799\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 15400; step_loss: 0.2263 (0.2233, 0.0030)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         15400\n","Learning rate:       0.0000\n","Train loss avg:      0.2389\n","--------------------------\n","Val loss:            0.2928\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 15500; step_loss: 0.2380 (0.2359, 0.0021)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         15500\n","Learning rate:       0.0000\n","Train loss avg:      0.2471\n","--------------------------\n","Val loss:            0.2942\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 15600; step_loss: 0.2498 (0.2467, 0.0031)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         15600\n","Learning rate:       0.0000\n","Train loss avg:      0.2422\n","--------------------------\n","Val loss:            0.2494\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 15700; step_loss: 0.1985 (0.1960, 0.0025)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         15700\n","Learning rate:       0.0000\n","Train loss avg:      0.2385\n","--------------------------\n","Val loss:            0.2730\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 15800; step_loss: 0.2187 (0.2172, 0.0016)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         15800\n","Learning rate:       0.0000\n","Train loss avg:      0.2439\n","--------------------------\n","Val loss:            0.2238\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 15900; step_loss: 0.2482 (0.2464, 0.0018)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         15900\n","Learning rate:       0.0000\n","Train loss avg:      0.2461\n","--------------------------\n","Val loss:            0.2732\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 16000; step_loss: 0.2464 (0.2446, 0.0017)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         16000\n","Learning rate:       0.0000\n","Train loss avg:      0.2425\n","--------------------------\n","Val loss:            0.2805\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 16100; step_loss: 0.2168 (0.2152, 0.0016)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         16100\n","Learning rate:       0.0000\n","Train loss avg:      0.2410\n","--------------------------\n","Val loss:            0.2643\n","============================\n","\n","\n","============================\n","Global step:         16200\n","Learning rate:       0.0000\n","Train loss avg:      0.2413\n","--------------------------\n","Val loss:            0.2921\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 16200; step_loss: 0.2062 (0.2045, 0.0017)\n","INFO: step 16300; step_loss: 0.2137 (0.2124, 0.0014)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         16300\n","Learning rate:       0.0000\n","Train loss avg:      0.2419\n","--------------------------\n","Val loss:            0.2522\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 16400; step_loss: 0.2256 (0.2242, 0.0013)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         16400\n","Learning rate:       0.0000\n","Train loss avg:      0.2455\n","--------------------------\n","Val loss:            0.2510\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 16500; step_loss: 0.3091 (0.3074, 0.0017)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         16500\n","Learning rate:       0.0000\n","Train loss avg:      0.2399\n","--------------------------\n","Val loss:            0.3053\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 16600; step_loss: 0.2734 (0.2719, 0.0016)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         16600\n","Learning rate:       0.0000\n","Train loss avg:      0.2459\n","--------------------------\n","Val loss:            0.2910\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 16700; step_loss: 0.2295 (0.2283, 0.0012)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         16700\n","Learning rate:       0.0000\n","Train loss avg:      0.2382\n","--------------------------\n","Val loss:            0.3182\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 16800; step_loss: 0.2280 (0.2269, 0.0011)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         16800\n","Learning rate:       0.0000\n","Train loss avg:      0.2440\n","--------------------------\n","Val loss:            0.2792\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 16900; step_loss: 0.2165 (0.2154, 0.0011)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         16900\n","Learning rate:       0.0000\n","Train loss avg:      0.2410\n","--------------------------\n","Val loss:            0.2770\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 17000; step_loss: 0.2251 (0.2241, 0.0010)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         17000\n","Learning rate:       0.0000\n","Train loss avg:      0.2387\n","--------------------------\n","Val loss:            0.3202\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 17100; step_loss: 0.2792 (0.2781, 0.0011)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         17100\n","Learning rate:       0.0000\n","Train loss avg:      0.2441\n","--------------------------\n","Val loss:            0.2568\n","============================\n","\n","\n","============================\n","Global step:         17200\n","Learning rate:       0.0000\n","Train loss avg:      0.2443\n","--------------------------\n","Val loss:            0.2721\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 17200; step_loss: 0.2079 (0.2069, 0.0010)\n","INFO: step 17300; step_loss: 0.2033 (0.2024, 0.0010)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         17300\n","Learning rate:       0.0000\n","Train loss avg:      0.2372\n","--------------------------\n","Val loss:            0.2784\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 17400; step_loss: 0.2065 (0.2057, 0.0008)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         17400\n","Learning rate:       0.0000\n","Train loss avg:      0.2399\n","--------------------------\n","Val loss:            0.2799\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 17500; step_loss: 0.2312 (0.2304, 0.0008)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         17500\n","Learning rate:       0.0000\n","Train loss avg:      0.2361\n","--------------------------\n","Val loss:            0.2713\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 17600; step_loss: 0.1987 (0.1981, 0.0006)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         17600\n","Learning rate:       0.0000\n","Train loss avg:      0.2401\n","--------------------------\n","Val loss:            0.2963\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 17700; step_loss: 0.2199 (0.2190, 0.0009)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         17700\n","Learning rate:       0.0000\n","Train loss avg:      0.2422\n","--------------------------\n","Val loss:            0.3176\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 17800; step_loss: 0.2464 (0.2458, 0.0006)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         17800\n","Learning rate:       0.0000\n","Train loss avg:      0.2379\n","--------------------------\n","Val loss:            0.3044\n","============================\n","\n","\n","============================\n","Global step:         17900\n","Learning rate:       0.0000\n","Train loss avg:      0.2361\n","--------------------------\n","Val loss:            0.2635\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 17900; step_loss: 0.2811 (0.2805, 0.0006)\n","INFO: step 18000; step_loss: 0.3224 (0.3217, 0.0007)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         18000\n","Learning rate:       0.0000\n","Train loss avg:      0.2417\n","--------------------------\n","Val loss:            0.3210\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 18100; step_loss: 0.2143 (0.2138, 0.0006)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         18100\n","Learning rate:       0.0000\n","Train loss avg:      0.2355\n","--------------------------\n","Val loss:            0.3012\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 18200; step_loss: 0.2124 (0.2119, 0.0005)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         18200\n","Learning rate:       0.0000\n","Train loss avg:      0.2376\n","--------------------------\n","Val loss:            0.2747\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 18300; step_loss: 0.2592 (0.2588, 0.0005)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         18300\n","Learning rate:       0.0000\n","Train loss avg:      0.2455\n","--------------------------\n","Val loss:            0.2817\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 18400; step_loss: 0.2637 (0.2632, 0.0005)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         18400\n","Learning rate:       0.0000\n","Train loss avg:      0.2373\n","--------------------------\n","Val loss:            0.2967\n","============================\n","\n","\n","============================\n","Global step:         18500\n","Learning rate:       0.0000\n","Train loss avg:      0.2397\n","--------------------------\n","Val loss:            0.2671\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 18500; step_loss: 0.2362 (0.2358, 0.0005)\n","INFO: step 18600; step_loss: 0.3264 (0.3260, 0.0004)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         18600\n","Learning rate:       0.0000\n","Train loss avg:      0.2359\n","--------------------------\n","Val loss:            0.2931\n","============================\n","\n","\n","============================\n","Global step:         18700\n","Learning rate:       0.0000\n","Train loss avg:      0.2398\n","--------------------------\n","Val loss:            0.2728\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 18700; step_loss: 0.2227 (0.2222, 0.0005)\n","INFO: step 18800; step_loss: 0.2901 (0.2897, 0.0004)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         18800\n","Learning rate:       0.0000\n","Train loss avg:      0.2400\n","--------------------------\n","Val loss:            0.2680\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 18900; step_loss: 0.2003 (0.2000, 0.0003)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         18900\n","Learning rate:       0.0000\n","Train loss avg:      0.2386\n","--------------------------\n","Val loss:            0.2751\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 19000; step_loss: 0.2728 (0.2725, 0.0004)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         19000\n","Learning rate:       0.0000\n","Train loss avg:      0.2349\n","--------------------------\n","Val loss:            0.2662\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 19100; step_loss: 0.2837 (0.2834, 0.0003)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         19100\n","Learning rate:       0.0000\n","Train loss avg:      0.2387\n","--------------------------\n","Val loss:            0.2962\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 19200; step_loss: 0.2487 (0.2485, 0.0002)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         19200\n","Learning rate:       0.0000\n","Train loss avg:      0.2382\n","--------------------------\n","Val loss:            0.2634\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 19300; step_loss: 0.2583 (0.2580, 0.0004)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         19300\n","Learning rate:       0.0000\n","Train loss avg:      0.2418\n","--------------------------\n","Val loss:            0.2704\n","============================\n","\n","\n","============================\n","Global step:         19400\n","Learning rate:       0.0000\n","Train loss avg:      0.2379\n","--------------------------\n","Val loss:            0.2725\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 19400; step_loss: 0.2335 (0.2332, 0.0003)\n","INFO: step 19500; step_loss: 0.2145 (0.2143, 0.0002)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         19500\n","Learning rate:       0.0000\n","Train loss avg:      0.2331\n","--------------------------\n","Val loss:            0.3079\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 19600; step_loss: 0.2301 (0.2299, 0.0002)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         19600\n","Learning rate:       0.0000\n","Train loss avg:      0.2392\n","--------------------------\n","Val loss:            0.2863\n","============================\n","\n","\n","============================\n","Global step:         19700\n","Learning rate:       0.0000\n","Train loss avg:      0.2337\n","--------------------------\n","Val loss:            0.2667\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 19700; step_loss: 0.2717 (0.2715, 0.0002)\n","INFO: step 19800; step_loss: 0.2061 (0.2060, 0.0002)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         19800\n","Learning rate:       0.0000\n","Train loss avg:      0.2386\n","--------------------------\n","Val loss:            0.2872\n","============================\n","\n"]},{"name":"stderr","output_type":"stream","text":["INFO: step 19900; step_loss: 0.2165 (0.2164, 0.0002)\n"]},{"name":"stdout","output_type":"stream","text":["\n","============================\n","Global step:         19900\n","Learning rate:       0.0000\n","Train loss avg:      0.2329\n","--------------------------\n","Val loss:            0.2590\n","============================\n","\n","Decay learning rate. New value at 9.025e-06\n","\n","============================\n","Global step:         20000\n","Learning rate:       0.0000\n","Train loss avg:      0.2416\n","--------------------------\n","Val loss:            0.3410\n","============================\n","\n"]}],"source":["for _ in range(args['iterations']):\n","\toptimiser.zero_grad()\n","\t# Set a flag to compute gradients\n","\tmodel.train()\n","\t# === Training step ===\n","\n","\t# Get batch from the training set\n","\tencoder_inputs, decoder_inputs, decoder_outputs = model.get_batch(train_set,actions,device)\n","\n","\t# Forward pass\n","\tpreds, mu, logvar = model(encoder_inputs, decoder_inputs,device)\n","\n","\t# Loss: Mean Squared Errors\n","\trec_loss = (preds-decoder_outputs)**2\n","\trec_loss = rec_loss.mean()\n","\tkld_loss = -0.5 * (1 + logvar - mu**2 - torch.exp(logvar))\n","\tkld_loss = torch.mean(torch.sum(kld_loss, axis=1))\n","\tstep_loss = kld_loss + rec_loss\n","\tval_loss  = step_loss.mean()\n","\n","\t# step_loss = (preds-decoder_outputs)**2\n","\t# step_loss = step_loss.mean()\n","\n","\t# Backpropagation\n","\tstep_loss.backward()\n","\t# Gradient descent step\n","\toptimiser.step()\n","\n","\tstep_loss = step_loss.cpu().data.numpy()\n","\n","\tif current_step % 100 == 0:\n","\t\tlogging.info(\"step {0:04d}; step_loss: {1:.4f} ({2:.4f}, {3:.4f})\".format(current_step, step_loss, rec_loss.cpu().data.numpy(), kld_loss.cpu().data.numpy()))\n","\tloss += step_loss / args['test_every']\n","\tcurrent_step += 1\n","\t# === step decay ===\n","\tif current_step % args['learning_rate_step'] == 0:\n","\t\targs['learning_rate'] = args['learning_rate']*args['learning_rate_decay_factor']\n","\t\toptimiser = optim.Adam(model.parameters(),lr=args['learning_rate'], betas = (0.9, 0.999))\n","\t\tprint(\"Decay learning rate. New value at \" + str(args['learning_rate']))\n","\n","\t# Once in a while, save checkpoint, print statistics.\n","\tif current_step % args['test_every'] == 0:\n","\t\tmodel.eval()\n","\t\t# === Validation ===\n","\t\tencoder_inputs, decoder_inputs, decoder_outputs = model.get_batch(test_set,actions,device)\n","\t\tpreds, mu, logvar = model(encoder_inputs, decoder_inputs, device)\n","\n","\t\tstep_loss = (preds-decoder_outputs)**2\n","\t\t# kld_loss =-0.5 * (1 + logvar - mu**2 - torch.exp(logvar))\n","\t\t# step_loss = torch.mean(torch.sum(kld_loss, axis=1)) + rec_loss\n","\t\tval_loss  = step_loss.mean()\n","\n","\t\tprint(\"\\n============================\\n\"\n","\t\t\t\"Global step:         %d\\n\"\n","\t\t\t\"Learning rate:       %.4f\\n\"\n","\t\t\t\"Train loss avg:      %.4f\\n\"\n","\t\t\t\"--------------------------\\n\"\n","\t\t\t\"Val loss:            %.4f\\n\"\n","\t\t\t\"============================\\n\" % (current_step,\n","\t\t\targs['learning_rate'], loss,val_loss))\n","\t\tall_val_losses.append([current_step,val_loss.cpu().detach().numpy()])\n","\t\tall_losses.append([current_step,loss])\n","\t\ttorch.save(model, train_dir + '/model_' + str(current_step))\n","\t\t# Reset loss\n","\t\tloss = 0"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1668791341647,"user":{"displayName":"Jaime Francisco Aguayo Gonz�lez","userId":"07613071985857863916"},"user_tz":360},"id":"ZeMdq9wTlev2"},"outputs":[],"source":["vlosses = np.array(all_val_losses)\n","tlosses = np.array(all_losses)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"elapsed":312,"status":"ok","timestamp":1668791341947,"user":{"displayName":"Jaime Francisco Aguayo Gonz�lez","userId":"07613071985857863916"},"user_tz":360},"id":"EjWt-YHglev2","outputId":"097afa69-c7e9-46b1-84ff-f2c17909672c"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# Plot losses\n","plt.plot(vlosses[:,0],vlosses[:,1],'b')\n","plt.plot(tlosses[:,0],tlosses[:,1],'r')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":177,"status":"ok","timestamp":1668791365246,"user":{"displayName":"Jaime Francisco Aguayo Gonz�lez","userId":"07613071985857863916"},"user_tz":360},"id":"6ndbQWx_q5yZ"},"outputs":[],"source":["np.save(\"CVAE02.npy\", vlosses)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":189,"status":"ok","timestamp":1668791366359,"user":{"displayName":"Jaime Francisco Aguayo Gonz�lez","userId":"07613071985857863916"},"user_tz":360},"id":"gZgvfiK3lev3","outputId":"654619c9-9888-4b4f-a178-d3577dab978e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Parámeters: 1,754,181\n"]}],"source":["n_params = 0\n","for p in model.parameters():\n","    n_params += np.prod(p.shape)\n","\n","print(\"Parámeters: {0:,}\".format(n_params)) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ylhCQN1t3Dh"},"outputs":[],"source":["bl = np.load(\"CVAE02.npy\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.min(bl)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.8 ('torchy')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"ada64bb7d40a21713047ab4b20334d09c5185b9e82a42be51d9f161e907a7ce9"}}},"nbformat":4,"nbformat_minor":0}
